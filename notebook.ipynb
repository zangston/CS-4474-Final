{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS 4774: Final Project\n",
        "Final project report by Ben Tyeyar (bat8hgp), Nick Teller (nst6tx), and Winston Zhang (wyz5rge)"
      ],
      "metadata": {
        "id": "vWsmkLml192i"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxP8lKbluoce"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FpHdAjbiuocm",
        "outputId": "daaf4ab8-2994-4fc2-8798-a53c6a18e70e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          URL  URL_LENGTH  NUMBER_SPECIAL_CHARACTERS     CHARSET  \\\n",
            "0      M0_109          16                          7  iso-8859-1   \n",
            "1     B0_2314          16                          6       UTF-8   \n",
            "2      B0_911          16                          6    us-ascii   \n",
            "3      B0_113          17                          6  ISO-8859-1   \n",
            "4      B0_403          17                          6       UTF-8   \n",
            "...       ...         ...                        ...         ...   \n",
            "1776    M4_48         194                         16       UTF-8   \n",
            "1777    M4_41         198                         17       UTF-8   \n",
            "1778   B0_162         201                         34       utf-8   \n",
            "1779  B0_1152         234                         34  ISO-8859-1   \n",
            "1780   B0_676         249                         40       utf-8   \n",
            "\n",
            "                      SERVER  CONTENT_LENGTH WHOIS_COUNTRY WHOIS_STATEPRO  \\\n",
            "0                      nginx           263.0          None           None   \n",
            "1              Apache/2.4.10         15087.0          None           None   \n",
            "2      Microsoft-HTTPAPI/2.0           324.0          None           None   \n",
            "3                      nginx           162.0            US             AK   \n",
            "4                       None        124140.0            US             TX   \n",
            "...                      ...             ...           ...            ...   \n",
            "1776                  Apache             NaN            ES      Barcelona   \n",
            "1777                  Apache             NaN            ES      Barcelona   \n",
            "1778  Apache/2.2.16 (Debian)          8904.0            US             FL   \n",
            "1779        cloudflare-nginx             NaN            US             CA   \n",
            "1780       Microsoft-IIS/8.5         24435.0            US      Wisconsin   \n",
            "\n",
            "         WHOIS_REGDATE WHOIS_UPDATED_DATE  ...  DIST_REMOTE_TCP_PORT  \\\n",
            "0     10/10/2015 18:21               None  ...                     0   \n",
            "1                 None               None  ...                     7   \n",
            "2                 None               None  ...                     0   \n",
            "3       7/10/1997 4:00    12/09/2013 0:45  ...                    22   \n",
            "4      12/05/1996 0:00    11/04/2017 0:00  ...                     2   \n",
            "...                ...                ...  ...                   ...   \n",
            "1776   17/09/2008 0:00     2/09/2016 0:00  ...                     0   \n",
            "1777   17/09/2008 0:00     2/09/2016 0:00  ...                     0   \n",
            "1778   15/02/1999 0:00    15/07/2015 0:00  ...                     2   \n",
            "1779    1/04/1998 0:00     9/12/2016 0:00  ...                     0   \n",
            "1780   14/11/2008 0:00    20/11/2013 0:00  ...                     6   \n",
            "\n",
            "      REMOTE_IPS  APP_BYTES  SOURCE_APP_PACKETS  REMOTE_APP_PACKETS  \\\n",
            "0              2        700                   9                  10   \n",
            "1              4       1230                  17                  19   \n",
            "2              0          0                   0                   0   \n",
            "3              3       3812                  39                  37   \n",
            "4              5       4278                  61                  62   \n",
            "...          ...        ...                 ...                 ...   \n",
            "1776           0          0                   0                   3   \n",
            "1777           0          0                   0                   2   \n",
            "1778           6       6631                  87                  89   \n",
            "1779           0          0                   0                   0   \n",
            "1780          11       2314                  25                  28   \n",
            "\n",
            "      SOURCE_APP_BYTES  REMOTE_APP_BYTES  APP_PACKETS  DNS_QUERY_TIMES  Type  \n",
            "0                 1153               832            9              2.0     1  \n",
            "1                 1265              1230           17              0.0     0  \n",
            "2                    0                 0            0              0.0     0  \n",
            "3                18784              4380           39              8.0     0  \n",
            "4               129889              4586           61              4.0     0  \n",
            "...                ...               ...          ...              ...   ...  \n",
            "1776               186                 0            0              0.0     1  \n",
            "1777               124                 0            0              0.0     1  \n",
            "1778            132181              6945           87              4.0     0  \n",
            "1779                 0                 0            0              0.0     0  \n",
            "1780              3039              2776           25              6.0     0  \n",
            "\n",
            "[1781 rows x 21 columns]\n",
            "      Type\n",
            "0        1\n",
            "1        0\n",
            "2        0\n",
            "3        0\n",
            "4        0\n",
            "...    ...\n",
            "1776     1\n",
            "1777     1\n",
            "1778     0\n",
            "1779     0\n",
            "1780     0\n",
            "\n",
            "[1781 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/zangston/CS-4474-Final/main/dataset.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# print(data)\n",
        "\n",
        "'''\n",
        "Split dataset into X_data and Y_data. Y is a boolean value that assigns the\n",
        "status of a website, whether it's malicious or benign.\n",
        "'''\n",
        "X_data = data.iloc[:,:-1]\n",
        "Y_data = data.iloc[:,-1:]\n",
        "\n",
        "print(X_data)\n",
        "print(Y_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mStn0iBhuoco"
      },
      "source": [
        "# Section 1: Data Preprocessing\n",
        "Our selection for the preprocessing of the \"Malicious and Benign Websites\" dataset is OneHotEncoding. The dataset contains mainy columns that contain categorical data, such as \"CHARSET\", which contains data like \"ascii\" or \"UTF-8\". OrdinalEncoding is another option for categorical data; however, it is a better fit when there is some sort of ordering to the data -- such as the categories being \"small\", \"medium\", \"large\" -- and is not as good of a fit for data with no ordering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "mE2h0BOfuocp",
        "outputId": "294a9aa5-de51-4478-a10d-32ec1dde2b36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 1574)\t1.0\n",
            "  (0, 1781)\t1.0\n",
            "  (0, 1925)\t1.0\n",
            "  (0, 1958)\t1.0\n",
            "  (0, 2163)\t1.0\n",
            "  (0, 2263)\t1.0\n",
            "  (0, 2870)\t1.0\n",
            "  (0, 2988)\t1.0\n",
            "  (0, 3131)\t1.0\n",
            "  (0, 4556)\t1.0\n",
            "  (0, 4564)\t1.0\n",
            "  (0, 4660)\t1.0\n",
            "  (0, 4728)\t1.0\n",
            "  (0, 4808)\t1.0\n",
            "  (0, 5578)\t1.0\n",
            "  (0, 5692)\t1.0\n",
            "  (0, 5954)\t1.0\n",
            "  (0, 6759)\t1.0\n",
            "  (0, 7514)\t1.0\n",
            "  (0, 7619)\t1.0\n",
            "  (1, 796)\t1.0\n",
            "  (1, 1781)\t1.0\n",
            "  (1, 1924)\t1.0\n",
            "  (1, 1957)\t1.0\n",
            "  (1, 2024)\t1.0\n",
            "  :\t:\n",
            "  (1779, 5682)\t1.0\n",
            "  (1779, 5798)\t1.0\n",
            "  (1779, 6683)\t1.0\n",
            "  (1779, 7505)\t1.0\n",
            "  (1779, 7618)\t1.0\n",
            "  (1780, 1246)\t1.0\n",
            "  (1780, 1922)\t1.0\n",
            "  (1780, 1952)\t1.0\n",
            "  (1780, 1960)\t1.0\n",
            "  (1780, 2084)\t1.0\n",
            "  (1780, 2731)\t1.0\n",
            "  (1780, 2883)\t1.0\n",
            "  (1780, 3051)\t1.0\n",
            "  (1780, 3232)\t1.0\n",
            "  (1780, 4220)\t1.0\n",
            "  (1780, 4576)\t1.0\n",
            "  (1780, 4666)\t1.0\n",
            "  (1780, 4737)\t1.0\n",
            "  (1780, 5146)\t1.0\n",
            "  (1780, 5594)\t1.0\n",
            "  (1780, 5710)\t1.0\n",
            "  (1780, 6110)\t1.0\n",
            "  (1780, 7109)\t1.0\n",
            "  (1780, 7530)\t1.0\n",
            "  (1780, 7621)\t1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(X_data)\n",
        "# print(enc.categories_)\n",
        "# print(X_data)\n",
        "\n",
        "X_encoded = enc.transform(X_data)\n",
        "\n",
        "print(X_encoded)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5WVRgytuocr"
      },
      "source": [
        "# Section 2: Data Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "eQuUjBXIuocs",
        "outputId": "a56313b5-f52d-4e63-8144-50e96313c2b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 1036)\t1.0\n",
            "  (0, 1802)\t1.0\n",
            "  (0, 1926)\t1.0\n",
            "  (0, 1957)\t1.0\n",
            "  (0, 2163)\t1.0\n",
            "  (0, 2840)\t1.0\n",
            "  (0, 2883)\t1.0\n",
            "  (0, 2903)\t1.0\n",
            "  (0, 3335)\t1.0\n",
            "  (0, 4167)\t1.0\n",
            "  (0, 4601)\t1.0\n",
            "  (0, 4660)\t1.0\n",
            "  (0, 4730)\t1.0\n",
            "  (0, 5340)\t1.0\n",
            "  (0, 5617)\t1.0\n",
            "  (0, 5730)\t1.0\n",
            "  (0, 6649)\t1.0\n",
            "  (0, 7269)\t1.0\n",
            "  (0, 7553)\t1.0\n",
            "  (0, 7620)\t1.0\n",
            "  (1, 90)\t1.0\n",
            "  (1, 1813)\t1.0\n",
            "  (1, 1929)\t1.0\n",
            "  (1, 1957)\t1.0\n",
            "  (1, 2163)\t1.0\n",
            "  :\t:\n",
            "  (1422, 5714)\t1.0\n",
            "  (1422, 6341)\t1.0\n",
            "  (1422, 7250)\t1.0\n",
            "  (1422, 7539)\t1.0\n",
            "  (1422, 7622)\t1.0\n",
            "  (1423, 108)\t1.0\n",
            "  (1423, 1823)\t1.0\n",
            "  (1423, 1926)\t1.0\n",
            "  (1423, 1957)\t1.0\n",
            "  (1423, 1970)\t1.0\n",
            "  (1423, 2213)\t1.0\n",
            "  (1423, 2883)\t1.0\n",
            "  (1423, 2948)\t1.0\n",
            "  (1423, 3171)\t1.0\n",
            "  (1423, 4274)\t1.0\n",
            "  (1423, 4557)\t1.0\n",
            "  (1423, 4660)\t1.0\n",
            "  (1423, 4726)\t1.0\n",
            "  (1423, 4744)\t1.0\n",
            "  (1423, 5569)\t1.0\n",
            "  (1423, 5682)\t1.0\n",
            "  (1423, 5798)\t1.0\n",
            "  (1423, 6683)\t1.0\n",
            "  (1423, 7505)\t1.0\n",
            "  (1423, 7618)\t1.0       Type\n",
            "365      0\n",
            "828      0\n",
            "1547     0\n",
            "1237     0\n",
            "1137     0\n",
            "...    ...\n",
            "1320     0\n",
            "1576     0\n",
            "1079     0\n",
            "1035     1\n",
            "1131     0\n",
            "\n",
            "[1424 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_trn, x_part, y_trn, y_part = train_test_split(X_encoded, Y_data,train_size=0.8,random_state=71)\n",
        "\n",
        "print(x_trn,y_trn)\n",
        "\n",
        "x_test, x_val, y_test, y_val = train_test_split(x_part,y_part,train_size=0.5, random_state=71)\n",
        "\n",
        "#print(x_test,y_test)\n",
        "#print(x_val,y_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxeVyr_Buocu"
      },
      "source": [
        "# Section 3: Build Classifiers\n",
        "The classifiers we have chosen to use for this project are SVM and Feed-forward Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VMq7T4hluocw",
        "outputId": "6845ee28-94d7-4452-a250-c1fc13725370",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM accurary with default parameters: 0.9497206703910615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "SVM_clf = SVC()\n",
        "\n",
        "SVM_clf.fit(x_trn,y_trn)\n",
        "\n",
        "svm_acc = SVM_clf.score(x_val,y_val)\n",
        "\n",
        "print(\"SVM accurary with default parameters:\",svm_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-vBF1rPQuocy",
        "outputId": "0e426ede-5106-4a2a-9e25-6be3e409cd63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural Network accuracy with default paramters: 0.9441340782122905\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "Neural_clf = MLPClassifier()\n",
        "\n",
        "Neural_clf.fit(x_trn,y_trn)\n",
        "\n",
        "neural_acc = Neural_clf.score(x_val,y_val)\n",
        "\n",
        "print(\"Neural Network accuracy with default paramters:\",neural_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axg9acOluocz"
      },
      "source": [
        "# Section 4: Hyperparameter Tuning\n",
        "For the SVM, the hyperparameters that we will be tuning are the C value, the kernel, and the Gamma value.\n",
        "For the Neural Network, the hyperameters that will be tuning are the alpha value, the learning rate, and the hidden_layer_sizes.\n",
        "\n",
        "For both classifiers, we will be using a grid search to tune the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14vZtqZWuoc2",
        "outputId": "27ebfe9c-d0bc-45a3-9374-cdfe4107cf4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', message='A column-vector y was passed when a 1d array was expected.*')\n",
        "param_grid = {'C': [0.1, 1, 10, 100],\n",
        "              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "              'gamma': ['scale', 'auto'] + list(np.logspace(-3, 3, 7))}\n",
        "\n",
        "grid_search = GridSearchCV(SVC(),param_grid,cv=5)\n",
        "grid_search.fit(x_trn,y_trn)\n",
        "\n",
        "print(grid_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wtFIfHBuoc2",
        "outputId": "f31b7856-26ed-48ea-d0ff-c81a7eaf3eda"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\benty\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\benty\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\benty\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\benty\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\benty\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\benty\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\benty\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\benty\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\benty\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\benty\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\benty\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\benty\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\benty\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'alpha': 1, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "params = {'alpha': [0.01, 0.1, 1],\n",
        "          'learning_rate': ['constant', 'adaptive'],\n",
        "          'hidden_layer_sizes': [(10,), (50,), (100,), (10,10), (50,50), (100,100)]}\n",
        "\n",
        "grid_search = GridSearchCV(MLPClassifier(),params,cv=5)\n",
        "grid_search.fit(x_trn,y_trn)\n",
        "\n",
        "print(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 5: Anaylsis\n",
        "**Based on the results above, which classifier is better, and why?**\n",
        "\n",
        "Based on the accuracy scores computed after building our classifiers in Section 3, we observe an accuracy score of 94.97% for the SVM and 93.85% for the neural network. This means that the SVM is the better classifier as it performed slightly better than the neural network. This may be because of the categorical nature of the data, which the SVM, who uses a hyperplane to classify data, was slightly better equipped to process. SVMs are thus known to work well with datasets with many dimension. Neural networks, on the other hand, struggle with such dimensionality.\n",
        "\n",
        "**For further improvement on classification accuracy, what strategies can you use and why do you think they will be helpful?**\n",
        "\n",
        "One strategy that could be used is to increase the size of the dataset. Obviously, giving the classifier more data will allow it to have a better fit. This is because the Law of Large Numbers dictates that such functions will converge to an average form as the sample size grows large. As all statisticians and data scientists know, while this is the simplest and easy solution, this might not always be possible, as data collection can become a very expensive process.\n",
        "\n",
        "Another strategy is to use ensemble methods, e.g., bagging or boosting. As suggested by the name, ensemble methods combine the predictions of several classifiers. When we elect to do this, we are less constrained by the shortcomings of any one classifier, while benefitting from the merits of many. \"We get the best of both worlds\".\n",
        "\n",
        "**Which input feature is the most informative one, and what is your empirical evidence?**\n"
      ],
      "metadata": {
        "id": "tqAL-cGSz-lU"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}